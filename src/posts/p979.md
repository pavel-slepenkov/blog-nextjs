---
title: 'Setting up web scraping python environment on Google Compute Engine'
date: '2018-12-10T00:59:58+00:00'
status: publish
permalink: '/?p=979'
author: pavel
excerpt: ''
type: post
id: p979
category:
    - Uncategorized
tag:
    - 'google cloud platform'
    - postgres
    - python
post_format: []
---

> *Disclaimer: Nothing unique is described here. Post is made with intent to have a checklist of my setup. It’d be great if it might be interested or helpful to someone else*

One of my project requires a daily web scraping and storing data on database. Project includes the following components:

- Python 3.7
- Postgres
- Cron

Past years this project was running on AWS EC2 t2.micro instance and this was enough. I was going to switch from AWS to GCP in order to test and evaluate new service.

![Max. of CPU utilization on AWS EC2 micro](/images/p979/image-2-1024x478.png)
*Max. of CPU utilization on AWS EC2 micro*

<ps2>**1. Setup [Google Cloud Platform ](http://cloud.google.com)account**</ps2>

It’s super easy to fill in several forms and get your account.

<ps2>**2. Setup Debian machine.**</ps2>

I choose **g1-small** machine with 1 vCPU and 1.7 GB memory which should be enough for my experiments. During machine configuration process you can add your ssh key.

<ps2>**3. Connect via SSH.**</ps2>

After setup you can login with SSH directly from browser or by your preferable client with ssh key provided in the previous step

```bash
ssh -i "~/.ssh/id_rsa" pavel@2.248.5.16
```
where pavel is name which I give to my ssh key and 2.248.5.16 is public IP address of my instance.

After login to the newly created instance I have to setup all required tools

<ps2>**4. Python installation**</ps2>

Debian machine comes with Python 3.5 installed. My projects use python 3.7, so I need to install this Python version.

Install build-essential
```bash
sudo apt-get install build-essential
```

Build Python from sources

```bash
wget https://www.python.org/ftp/python/3.7.1/Python-3.7.1.tgz
tar xvf Python-3.7.1.tgz
cd Python-3.7.1
./configure --enable-optimizations
make -j8
sudo make altinstall
python3.7
```
*It took about 40 minutes on this machine*

![](/images/p979/image.png)<figcaption>CPU utilization during python compilation</figcaption>

<ps2>**5. Postgres installation**</ps2>

Official postgres site provides [great instruction](https://www.postgresql.org/download/linux/debian/) on how to install postgres version which you need.
create file

```bash
sudo vi /etc/apt/sources.list.d/pgdg.list
```

with the following content

```bash
deb http://apt.postgresql.org/pub/repos/apt/ stretch-pgdg main
```

Then run

```bash
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt-get update
apt-get install postgresql-11
```

After success Postgres installation we need to perform initial configuration. Setup postgres user password by the following command.

```bash
sudo -u postgres psql -c "ALTER USER postgres PASSWORD 'your_password';"
sudo vim /etc/postgresql/11/main/pg_hba.conf
```

change config file with the following values

```bash
# Database administrative login by Unix domain socket
local   all             postgres                                md5

# "local" is for Unix domain socket connections only
local   all             all                                     md5
```

Restart Postgres

```bash
sudo /etc/init.d/postgresql restart
```

Create new user for using in your development environment

```bash
createuser -U postgres -d -e -E -l -P -r -s <my_name>
```

<ps2>**6. Configure crontab**</ps2>

run `crontab -e` and add the following lines to its config

```bash
SHELL=/bin/bash
PYTHONIOENCODING=utf8
0 0 15 * * python /home/pavel/projects/p1/src/scraper1.py all
0 * * * * python /home/pavel/projects/p1/src/scraper1.py latest
0 * * * * python /home/pavel/projects/p1/src/s1/scraper2.py
```

<ps2>**7. Create a swap file**</ps2>

Google Cloud Compute vm had no swap file. So we need to create one

```bash
sudo dd if=/dev/zero of=/var/swap bs=2048 count=524288
sudo chmod 600 /var/swap
sudo mkswap /var/swap
sudo swapon /var/swap
```

And then the following line to /etc/fstab to make it permanent.

```bash
/var/swap none swap sw 0 0
```

That’s a complete setup of my web scraping environment. Here’s monitoring of web scraping activity

![](/images/p979/image-1.png)</figure>